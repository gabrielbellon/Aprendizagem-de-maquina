{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<br/>\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<center><i><b>\n",
    "Atenção: não são autorizadas cópias, divulgações ou qualquer tipo de uso deste material sem o consentimento prévio dos autores.\n",
    "</center></i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Exercício - Sistemas de Recomendação</center>\n",
    "\n",
    "Introdução\n",
    "----------\n",
    "Neste *notebook*, você fará um protocolo experimental completo no contexto de Sistemas de Recomendação, aplicando dois algoritmos de Filtragem Colaborativa, KNN e SVD, sobre uma base real de recomendação de filmes. Os experimentos que serão apresentados foram projetados com o intuito de facilitar o entendimento da área e serem genéricos, permitindo sua reprodução em outros domínios de aplicação.\n",
    "\n",
    "Antes de começar, é recomendável que você revise os conceitos apresentados em aula.\n",
    "\n",
    "\n",
    "## Instruções\n",
    "Este arquivo contém o código que auxiliará no desenvolvimento do exercício. Você precisará completar as seguintes funções:\n",
    "\n",
    "* <tt>knn()</tt>\n",
    "* <tt>svd_sgd_optimizer()</tt>\n",
    "* <tt>rmse_mae()</tt>\n",
    "* <tt>precision_recall_f1()</tt>\n",
    "* <tt>ndcg()</tt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Leitura e preparação da base de dados\n",
    "\n",
    "A base de dados utilizada nesse trabalho foi extraída do site [movielens.org](https://movielens.org). \n",
    "\n",
    "O **MovieLens** é um portal de recomendação de filmes gerenciado pelo grupo de pesquisa GroupLens, da Universidade de Minnesota. Diversas variações da base de dados encontram-se hospedadas no [site do grupo](https://grouplens.org/datasets/movielens/). Ao longo da disciplina, utilizaremos a **ml-latest-small**, versão reduzida, destinada para estudo.\n",
    "\n",
    "A base original possui diversos arquivos diferentes, seguindo um determinado padrão. Nem todos serão necessários para o trabalho. Iremos então formatar a base, selecionando apenas as informações relevantes. Adicionalmente, usaremos apenas 20% da base, com o intuito de reduzir o tempo de execução dos experimentos presentes no notebook.\n",
    "\n",
    "Um código para preprocessamento e formatação da base encontra-se na função `format_movielens_dataset()`, presente no arquivo `recsys_utils.py` enviado junto com este trabalho. Iremos executá-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando tratamento da base Movielens...\n",
      "\tTratando os itens...\n",
      "\tTratando os usuarios...\n",
      "\tTratando as interacoes...\n",
      "\tSalvando os arquivos tratados...\n",
      "Tudo OK!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Caminho dos arquivos\n",
    "FILES_DIRECTORY = \"ml-100k\"\n",
    "\n",
    "from recsys_utils import format_movielens_dataset\n",
    "\n",
    "format_movielens_dataset(raw_dataset_folder=FILES_DIRECTORY, sampling_rate=0.2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É fortemente encorajado que você olhe o código para entender o que foi realizado. Após sua chamada, **3** novos arquivos foram criados, dentro da pasta <tt>datasets</tt>. São eles:\n",
    "* **users.csv**: contendo informações sobre os usuários do sistema;\n",
    "* **items.csv**: contendo informações sobre os filmes do sistema;\n",
    "* **interactions.csv**: contendo todas as notas que os usuários deram aos filmes.\n",
    "\n",
    "Vamos carregar os arquivos como objetos `pandas.DataFrame` e visualizá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usuários:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_usuario</th>\n",
       "      <th>idade</th>\n",
       "      <th>genero</th>\n",
       "      <th>ocupacao</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_usuario  idade genero    ocupacao    zip\n",
       "0           1     24      M  technician  85711\n",
       "1           2     53      F       other  94043\n",
       "2           3     23      M      writer  32067\n",
       "3           4     24      M  technician  43537\n",
       "4           5     33      F       other  15213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Itens:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_item</th>\n",
       "      <th>titulo</th>\n",
       "      <th>ano</th>\n",
       "      <th>genero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>Animation/Children's/Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>1995</td>\n",
       "      <td>Action/Adventure/Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>1995</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty</td>\n",
       "      <td>1995</td>\n",
       "      <td>Action/Comedy/Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat</td>\n",
       "      <td>1995</td>\n",
       "      <td>Crime/Drama/Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_item       titulo   ano                       genero\n",
       "0        1   Toy Story   1995  Animation/Children's/Comedy\n",
       "1        2   GoldenEye   1995    Action/Adventure/Thriller\n",
       "2        3  Four Rooms   1995                     Thriller\n",
       "3        4  Get Shorty   1995          Action/Comedy/Drama\n",
       "4        5     Copycat   1995         Crime/Drama/Thriller"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interações:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_usuario</th>\n",
       "      <th>id_item</th>\n",
       "      <th>nota</th>\n",
       "      <th>data-hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1997-11-11 22:30:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1997-11-06 23:45:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269</td>\n",
       "      <td>444</td>\n",
       "      <td>3</td>\n",
       "      <td>1998-04-01 14:32:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>741</td>\n",
       "      <td>699</td>\n",
       "      <td>4</td>\n",
       "      <td>1998-03-27 14:06:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>527</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>1997-11-13 18:25:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_usuario  id_item  nota            data-hora\n",
       "0         283       70     4  1997-11-11 22:30:06\n",
       "1         213      100     5  1997-11-06 23:45:49\n",
       "2         269      444     3  1998-04-01 14:32:51\n",
       "3         741      699     4  1998-03-27 14:06:40\n",
       "4         527      156     3  1997-11-13 18:25:34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temos 939 usuários\n",
      "Temos 1393 itens\n",
      "Temos 19998 interações\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Carrega bases de dados\n",
    "users = pd.read_csv('dataset/users.csv', sep=';', quotechar='\"', quoting=csv.QUOTE_ALL, encoding='latin-1', header=0, index_col=None)\n",
    "items = pd.read_csv('dataset/items.csv', sep=';', quotechar='\"', quoting=csv.QUOTE_ALL, encoding='latin-1', header=0, index_col=None)\n",
    "interactions = pd.read_csv('dataset/interactions.csv', sep=';', quotechar='\"', quoting=csv.QUOTE_ALL, encoding='latin-1', header=0, index_col=None)\n",
    "\n",
    "# Preenche generos nulos\n",
    "items['genero'] = items['genero'].fillna('')\n",
    "\n",
    "# Exibe as 5 primeiras linhas de cada arquivo\n",
    "print('\\nUsuários:')\n",
    "display(users.head(5))\n",
    "print('\\nItens:')\n",
    "display(items.head(5))\n",
    "print('\\nInterações:')\n",
    "display(interactions.head(5))\n",
    "\n",
    "# Faz a contagem de usuarios, itens e interacoes\n",
    "n_users = len(users)\n",
    "n_items = len(items)\n",
    "n_interactions = len(interactions)\n",
    "print('Temos {} usuários'.format(len(users)))\n",
    "print('Temos {} itens'.format(len(items)))\n",
    "print('Temos {} interações\\n'.format(len(interactions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a base de dados carregada em memória, podemos ir para a segunda etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 2: Divisão da base em Treinamento, Validação e Teste\n",
    "\n",
    "Para treinar, ajustar os parâmetros e avaliar nossos modelos, iremos separar a base de dados usando _holdout_, com **80% dos dados para treinamento**, **10% para validação** e **10% para teste**. Para isso, usaremos a função `train_test_split()` da biblioteca `sklearn`. A função só consegue separar a base de dados em duas novas, não conseguindo assim separar em treino, validação e teste com uma única chamada. Iremos então extrair primeiramente as amostras de treinamento, separando o restante entre validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "interactions_train, remaining = train_test_split(\n",
    "    interactions,\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    shuffle=False\n",
    ")\n",
    "interactions_train = interactions_train.copy() # Apenas para evitar mensagens de warning adiante\n",
    "\n",
    "interactions_val, interactions_test = train_test_split(\n",
    "    remaining,\n",
    "    train_size=0.5,\n",
    "    test_size=0.5,\n",
    "    shuffle=False\n",
    ")\n",
    "interactions_val = interactions_val.copy() # Apenas para evitar mensagens de warning adiante\n",
    "interactions_test = interactions_test.copy() # Apenas para evitar mensagens de warning adiante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção do problema de Cold-Start na validação e teste\n",
    "\n",
    "Após a separação em treino-validação-teste, pode acontecer de clientes ou itens ficarem presentes apenas nas bases de teste, e ausentes na de treino. Esse é o problema do **cold-start**, ou partida fria, que deve ser abordado por algoritmos específicos (como baseados em conteúdo).\n",
    "\n",
    "Como este problema foge do escopo do notebook, vamos remover todos os casos de cold-start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nossa base de TREINAMENTO contém 15998 interações\n",
      "\n",
      "Nossa base de VALIDAÇÃO contém 1976 interações\n",
      "\n",
      "Nossa base de TESTE contém 1972 interações\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interactions_val = interactions_val[\n",
    "    (interactions_val['id_usuario'].isin(interactions_train['id_usuario']))\n",
    "    &(interactions_val['id_item'].isin(interactions_train['id_item']))\n",
    "].copy()\n",
    "\n",
    "interactions_test = interactions_test[\n",
    "    (interactions_test['id_usuario'].isin(interactions_train['id_usuario']))\n",
    "    &(interactions_test['id_item'].isin(interactions_train['id_item']))\n",
    "].copy()\n",
    "\n",
    "items = items[items['id_item'].isin(interactions_train['id_item'])]\n",
    "users = users[users['id_usuario'].isin(interactions_train['id_usuario'])]\n",
    "\n",
    "print('Nossa base de TREINAMENTO contém {} interações\\n'.format(len(interactions_train)))\n",
    "print('Nossa base de VALIDAÇÃO contém {} interações\\n'.format(len(interactions_val)))\n",
    "print('Nossa base de TESTE contém {} interações\\n'.format(len(interactions_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codifica IDs dos usuários e items para ficar no intervalo de 0 a N\n",
    "\n",
    "Para simplificar as implementações seguintes, iremos alterar os IDs dos usuários e itens, para que todos passem a variar no intervalo 0 a \"qtde. de usuários\" / \"qtde. de itens\". Com essa alteração, será mais fácil trabalhar com os dados em formato matricial, de forma que uma linhda de índice _i_ corresponda ao item _i_, por exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "item_encoder = LabelEncoder()    \n",
    "items.loc[:, 'id_item'] = item_encoder.fit_transform(items['id_item'].values)\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "users.loc[:, 'id_usuario'] = user_encoder.fit_transform(users['id_usuario'].values)\n",
    "\n",
    "interactions_train.loc[:, 'id_item'] = item_encoder.transform(interactions_train['id_item'].values)\n",
    "interactions_train.loc[:, 'id_usuario'] = user_encoder.transform(interactions_train['id_usuario'].values)\n",
    "\n",
    "interactions_val.loc[:, 'id_item'] = item_encoder.transform(interactions_val['id_item'].values)\n",
    "interactions_val.loc[:, 'id_usuario'] = user_encoder.transform(interactions_val['id_usuario'].values)\n",
    "\n",
    "interactions_test.loc[:, 'id_item'] = item_encoder.transform(interactions_test['id_item'].values)\n",
    "interactions_test.loc[:, 'id_usuario'] = user_encoder.transform(interactions_test['id_usuario'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 3: Implementação dos algoritmos de recomendação\n",
    "\n",
    "Serão implementados dois algoritmos diferentes, que utilizam dados explícitos para gerar a recomendação.\n",
    "* **K-Vizinhos Mais Próximos (KNN)**, baseado em vizinhança\n",
    "* **Decomposição em Valores Singulares (SVD)**, baseado em fatoração de matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>**KNN**</center>\n",
    "\n",
    "Para a implementação do KNN, primeiro iremos converter o DataFrame para uma matriz de interações, e então iremos gerar a recomendação como visto em aula:\n",
    "\n",
    "#### **Converter DataFrame para Matriz de Interações**\n",
    "\n",
    "Antes de implementar as funções de predição de nota pelo KNN, é necessário que nossos dados sejam representados como uma **Matriz de Interações**, onde cada linha corresponde a um item e cada coluna um usuário (ou o contrário). Com essa matriz, podemos recuperar os vetores de representação dos itens para o restante do algoritmo. Para isso, vamos transformar o dataframe de treino em uma matriz de interações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "interactions_matrix = np.zeros((n_items, n_users))\n",
    "interactions_matrix[interactions_train['id_item'], interactions_train['id_usuario']] = interactions_train['nota'].values\n",
    "print(interactions_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Predição de nota através do KNN**\n",
    "\n",
    "Com a matriz de interações, podemos realizar a predição das notas. A predição é composta de algums etapas, que você deverá implementar:\n",
    "\n",
    "* Calcular as similaridades entre os itens, o que pode ser feito usando `sklearn.metrics.pairwise.cosine_similarity`\n",
    "* Percorrer cada um dos pares usuário-item que se deseja prever uma nota\n",
    "* Encontrar os $k$ itens mais similares ao item alvo **dentre os itens que o usuário já avaliou**\n",
    "* Calcular a nota através da seguinte fórmula:\n",
    "\n",
    "$$R = \\frac{\\sum_{i=1}^{k}{(y_{u,i} \\times s_i)}}{\\sum_{i=1}^{k}{s_i}}$$\n",
    "\n",
    "Na qual, $y_{u,i}$ corresponde a nota atribuída pelo usuário ao item vizinho e $s_i$ representa a similaridade com o item alvo. Trata-se de uma simples média ponderada.\n",
    "\n",
    "Você deverá implementar a função `knn()`, que recebe as notas dadas pelos usuários num formato de matriz de interações, os pares usuário-item que se deseja prever uma nota e um valor de $k$.\n",
    "\n",
    "**Observações**\n",
    "* Para calcular as similaridades entre item, pode-se utilizar `sklearn.metrics.pairwise.cosine_similarity`\n",
    "* No caso de não ser possível calcular uma nota (todos os itens avaliados pelo usuário tem similaridade 0.0 em relação ao item alvo), preencha com o valor padrão **2.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se seu código estiver correto, a nota prevista será 4.2184\n",
      "A nota prevista foi 4.2184\n",
      "\n",
      "Se seu código estiver correto, a nota prevista será 3.4332\n",
      "A nota prevista foi 3.4332\n",
      "\n",
      "Se seu código estiver correto, a nota prevista será 3.8214\n",
      "A nota prevista foi 3.8214\n",
      "\n",
      "Se seu código estiver correto, a similaridade entre os itens 0 e 7 será 0.1687\n",
      "A similaridade é 0.1687\n",
      "\n",
      "Se seu código estiver correto, a similaridade entre os itens 101 e 368 será 0.4586\n",
      "A similaridade é 0.4586\n",
      "\n",
      "Se seu código estiver correto, a similaridade entre os itens 888 e 2 será 0.3588\n",
      "A similaridade é 0.3588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def knn(interactions_matrix, user_item_targets, k=10):\n",
    "    \"\"\"\n",
    "    Preve as notas que os usuarios dariam para os itens usando o algoritmo de KNN\n",
    "    \n",
    "    ----------- Entrada -----------\n",
    "       \n",
    "    interactions_matrix: matriz np.array contendo as representacoes vetoriais de cada item por linha\n",
    "    \n",
    "    user_item_targets: np.array contendo os pares usuario-item para prever a nota, no qual a\n",
    "        primeira coluna corresponde ao ID do usuario e a segunda coluna ao ID do item        \n",
    "    \n",
    "    k: numero de itens mais similares ao item alvo para observar\n",
    "    \n",
    "    ----------- Saída -----------\n",
    "    \n",
    "    item_sims: matriz contendo as similaridades entre items\n",
    "    \n",
    "    ratings: np.array de mesmo tamanho de user_item_targets contendo as notas previstas pelo KNN\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializa a matriz de similaridades\n",
    "    n_items, n_users = interactions_matrix.shape\n",
    "    item_sims = np.zeros((n_items, n_items))\n",
    "    \n",
    "    # Inicializa as notas\n",
    "    ratings = np.zeros(user_item_targets.shape[0])\n",
    "    \n",
    "    # Nota padrao\n",
    "    DEFAULT_RATING = 2.5\n",
    "        \n",
    "    ###########################################################################\n",
    "    ######################### COMPLETE O CÓDIGO AQUI  #########################\n",
    "    # Instruções: você deve prever as notas para os pares usuario-item contidos\n",
    "    #   em user_item_targets\n",
    "    #\n",
    "    # Para tal, calcula a similaridade entre os itens usando a funcao da \n",
    "    #   biblioteca sklearn cosine_similarity. Em seguida, para cada par\n",
    "    #   usuario-item, voce deve calcular a nota prevista usando os K itens\n",
    "    #   mais similares que o usuario ja avaliou\n",
    "    \n",
    "    item_sims = cosine_similarity(interactions_matrix)\n",
    "\n",
    "    for i, (user, item) in enumerate(user_item_targets):\n",
    "        interacted_items = np.where(interactions_matrix[:, user] > 0)[0]\n",
    "\n",
    "        k_itens = np.argsort(item_sims[item, interacted_items])[-k:]\n",
    "\n",
    "        ratings_top_k = interactions_matrix[interacted_items, user][k_itens]\n",
    "        sim_top_k = item_sims[item, interacted_items][k_itens]\n",
    "\n",
    "        if len(ratings_top_k) <= 0:\n",
    "            ratings[i] = DEFAULT_RATING\n",
    "        else:\n",
    "            ratings[i] = np.dot(ratings_top_k, sim_top_k) / np.sum(sim_top_k)\n",
    "\n",
    "    ###########################################################################\n",
    "    \n",
    "    return item_sims, ratings\n",
    "\n",
    "\n",
    "# Verifica a implementacao\n",
    "print(\"Se seu código estiver correto, a nota prevista será 4.2184\")\n",
    "item_sims, pred_rating = knn(interactions_matrix, np.array([[398,829]]), k=3)\n",
    "print(\"A nota prevista foi {:.4f}\\n\".format(pred_rating[0]))\n",
    "\n",
    "print(\"Se seu código estiver correto, a nota prevista será 3.4332\")\n",
    "item_sims, pred_rating = knn(interactions_matrix, np.array([[630,150]]), k=4)\n",
    "print(\"A nota prevista foi {:.4f}\\n\".format(pred_rating[0]))\n",
    "\n",
    "print(\"Se seu código estiver correto, a nota prevista será 3.8214\")\n",
    "item_sims, pred_rating = knn(interactions_matrix, np.array([[723,863]]), k=10)\n",
    "print(\"A nota prevista foi {:.4f}\\n\".format(pred_rating[0]))\n",
    "\n",
    "print(\"Se seu código estiver correto, a similaridade entre os itens 0 e 7 será 0.1687\")\n",
    "print(\"A similaridade é {:.4f}\\n\".format(item_sims[0, 7]))\n",
    "\n",
    "print(\"Se seu código estiver correto, a similaridade entre os itens 101 e 368 será 0.4586\")\n",
    "print(\"A similaridade é {:.4f}\\n\".format(item_sims[101, 368]))\n",
    "\n",
    "print(\"Se seu código estiver correto, a similaridade entre os itens 888 e 2 será 0.3588\")\n",
    "print(\"A similaridade é {:.4f}\\n\".format(item_sims[888, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> **SVD** </center>\n",
    "\n",
    "O segundo método será a técnica de fatoração de matrizes chamada de SVD, ou _Singular Value Decomposition_.\n",
    "\n",
    "Iremos otimizar o método através da abordagem **Stochastic Gradient Descent**, em que ambos os vetores de fatores latentes são otimizados simultaneamente.\n",
    "\n",
    "#### **Treinamento do SVD para ajuste de fatores latentes**\n",
    "\n",
    "Você deverá implementar a função `svd_sgd_optimizer()`, que recebe dois vetores de fatores latentes, de usuário e de item, assim como demais parâmetros da otimização e o valor-alvo (nota atribuída), e deve calcular os novos vetores de fatores latentes minimizando o erro, **utilizando regularização**.\n",
    "\n",
    "Primeiro, você deve calcular a diferença entre o valor real e a predição:\n",
    "\n",
    "$$e_{u,i} = y_{u,i} - p_uq_i^T$$\n",
    "\n",
    "Em seguida, você irá atualizar o conteúdo dos vetores de usuário ($p_u$) e item ($q_i$) com base em uma taxa de aprendizado $\\alpha$ e um fator de regularização $\\lambda$:\n",
    "\n",
    "$$p_{u} = p_{u} + \\alpha \\cdot (e_{u,i} \\cdot q_i - \\lambda \\cdot p_u)$$\n",
    "$$q_{i} = q_{i} + \\alpha \\cdot (e_{u,i} \\cdot p_u - \\lambda \\cdot q_i )$$\n",
    "\n",
    "**Importante**: a atualização de $p_u$ e $q_i$ deve ser feita **simultaneamente**. Assim, antes de atualizar o valor de qualquer um deles, você deve já ter calculado o gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se seu código estiver correto, o novo vetor do usuário será aprox.: [ 0.7775 -0.0998  2.1411]\n",
      "O novo vetor do usuário é [ 0.7775 -0.0998  2.1411]\n",
      "\n",
      "Se seu código estiver correto, o novo vetor do item será aprox.: [-0.66212 -0.64924  7.56924]\n",
      "O novo vetor do item é [-0.66212 -0.64924  7.56924]\n",
      "\n",
      "Se seu código estiver correto, o novo vetor do usuário será aprox.: [-0.59275 -0.0225   2.21825]\n",
      "O novo vetor do usuário é [-0.59275 -0.0225   2.21825]\n",
      "\n",
      "Se seu código estiver correto, o novo vetor do item será aprox.: [-0.36054 -2.25336  5.3657 ]\n",
      "O novo vetor do item é [-0.36054 -2.25336  5.3657 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def svd_sgd_optimizer(pu, qi, alpha_lr, lambda_reg, y):\n",
    "    \"\"\"\n",
    "    Ajusta os valores pu e qi simultaneamente para aproximá-los de y, utilizando regularização\n",
    "    \n",
    "    ----------- Entrada -----------\n",
    "       \n",
    "    pu e qi: vetores np.array com os fatores latentes do usuário e do item, respectivamente\n",
    "            - pu possui dimensões 1 x f, onde f é o número de fatores latentes\n",
    "            - qi possui dimensões 1 x f, onde f é o número de fatores latentes\n",
    "        \n",
    "    alpha_lr: número real representando a taxa de aprendizado\n",
    "    \n",
    "    lambda_reg: número real representando o fator de regularizacao\n",
    "    \n",
    "    y: nota que o usuário atribuiu ao item\n",
    "    \n",
    "    ----------- Saída -----------\n",
    "    \n",
    "    new_pu: novo vetor de fatores latentes do usuário\n",
    "    \n",
    "    new_qi: novo vetor de fatores latentes do item\n",
    "    \"\"\"\n",
    "    \n",
    "    new_pu = np.zeros(len(pu)) # Inicializa o novo vetor do usuario\n",
    "    new_qi = np.zeros(len(qi)) # Inicializa o novo vetor do item\n",
    "                   \n",
    "    ###########################################################################\n",
    "    ######################### COMPLETE O CÓDIGO AQUI  #########################\n",
    "    # Instruções: você deve calcular os novos valores para os vetores de fator\n",
    "    # latente do item e do usuário\n",
    "    #\n",
    "    # Importante: lembre de atualizar os dois vetores simultaneamentes, ou seja,\n",
    "    # não use o valor alterado de um dos vetores para atualizar o outro\n",
    "    #\n",
    "    \n",
    "    e_ui = y - np.dot(pu, qi.T)\n",
    "    new_pu = pu + alpha_lr * (np.dot(e_ui, qi) - lambda_reg * pu)\n",
    "    new_qi = qi + alpha_lr * (np.dot(e_ui, pu) - lambda_reg * qi)\n",
    "    \n",
    "    ###########################################################################\n",
    "    \n",
    "    return new_pu, new_qi\n",
    "\n",
    "\n",
    "# Verifica a implementacao\n",
    "\n",
    "# Inicializa vetores U e I aleatoriamente\n",
    "U = np.array([\n",
    "    [ 0.9,  0.6,  0.5], # Usuário 0\n",
    "    [-0.2,  0.3, -0.5], # Usuário 1\n",
    "    [ 2.8,  1.6, -0.1], # Usuário 2    \n",
    "])\n",
    "\n",
    "I = np.array([\n",
    "    [ 0.2,  9.3, -8.3], # Item 0\n",
    "    [-0.4, -2.3,  5.4], # Item 1\n",
    "    [-1.1, -0.9,  7.6], # Item 2    \n",
    "])\n",
    "\n",
    "print(\"Se seu código estiver correto, o novo vetor do usuário será aprox.: [ 0.7775 -0.0998  2.1411]\")\n",
    "new_pu, new_qi = svd_sgd_optimizer(pu=U[0], qi=I[1], alpha_lr=0.10, lambda_reg=0.01, y=4.0)\n",
    "print(\"O novo vetor do usuário é {}\\n\".format(new_pu))\n",
    "\n",
    "print(\"Se seu código estiver correto, o novo vetor do item será aprox.: [-0.66212 -0.64924  7.56924]\")\n",
    "new_pu, new_qi = svd_sgd_optimizer(pu=U[2], qi=I[2], alpha_lr=0.02, lambda_reg=0.1, y=2.5)\n",
    "print(\"O novo vetor do item é {}\\n\".format(new_qi))\n",
    "\n",
    "print(\"Se seu código estiver correto, o novo vetor do usuário será aprox.: [-0.59275 -0.0225   2.21825]\")\n",
    "new_pu, new_qi = svd_sgd_optimizer(pu=U[1], qi=I[2], alpha_lr=0.05, lambda_reg=0.05, y=3.3)\n",
    "print(\"O novo vetor do usuário é {}\\n\".format(new_pu))\n",
    "\n",
    "print(\"Se seu código estiver correto, o novo vetor do item será aprox.: [-0.36054 -2.25336  5.3657 ]\")\n",
    "new_pu, new_qi = svd_sgd_optimizer(pu=U[0], qi=I[1], alpha_lr=0.01, lambda_reg=1, y=4.9)\n",
    "print(\"O novo vetor do item é {}\\n\".format(new_qi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Predição de nota através do SVD**\n",
    "\n",
    "Em seguida, iremos implementar a função `svd()`, que irá utilizar sua função implementada na célula anterior.\n",
    "\n",
    "Esta função irá, ao longo de uma série de iterações, ajustar os fatores latentes de usuário e item para todas as interações e realizar a predição das notas para um conjunto de usuários-itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(interactions_matrix, user_item_targets, n_factors=100, n_epochs=10, alpha_lr=0.01, lambda_reg=0.01, verbose=True):\n",
    "    \n",
    "    # Inicializa os fatores latentes aleatoriamente\n",
    "    np.random.seed(0)\n",
    "    I = np.random.rand(interactions_matrix.shape[0], n_factors)\n",
    "    np.random.seed(0)\n",
    "    U = np.random.rand(interactions_matrix.shape[1], n_factors)\n",
    "    \n",
    "    ############################ TREINAMENTO ############################\n",
    "    \n",
    "    # Ao longo de N iterações...\n",
    "    for epc in range(n_epochs):\n",
    "        # Para cada interação...\n",
    "        all_interactions = interactions_matrix.nonzero()\n",
    "        for itr, (item, user) in enumerate(zip(*all_interactions), start=1):\n",
    "            if itr % 100 == 0 and verbose:\n",
    "                print(\"SVD - Iteração: {:02d}/{:02d}  |  Interação: {:05d}/{:05d}\".format(epc+1, n_epochs, itr, len(all_interactions[0])), end='\\r', flush=True)\n",
    "            # Recupera a nota\n",
    "            rating = interactions_matrix[item, user]\n",
    "            # Calcula novos vetores de fatores latentes\n",
    "            new_pu, new_qi = svd_sgd_optimizer(U[user], I[item], alpha_lr, lambda_reg, rating)\n",
    "            # Atualiza vetores de fatores latentes\n",
    "            U[user] = new_pu\n",
    "            I[item] = new_qi\n",
    "        if verbose:\n",
    "            print(\"SVD - Iteração: {:02d}/{:02d}  |  Interação: {:05d}/{:05d}\".format(epc+1, n_epochs, itr, len(all_interactions[0])), end='\\r', flush=True)\n",
    "       \n",
    "    ############################ PREDICAO DA NOTA ############################\n",
    "    \n",
    "    all_ratings = np.clip(np.dot(U, I.T), a_min=1, a_max=5) # Delimita a predição dentro do intervalo de notas\n",
    "    ratings = all_ratings[user_item_targets[:,0], user_item_targets[:,1]]\n",
    "    \n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 4: Métricas de avaliação\n",
    "\n",
    "Com nossos algoritmos implementados, estamos prontos para recomendar. Entretanto, como podemos saber qual algoritmo foi melhor? Para isso, são usadas métricas de avaliação.\n",
    "\n",
    "Iremos implementar duas famílias diferentes de métricas avaliativas: aquelas que medem a qualidade de um algoritmo para prever notas, e as que medem a qualidade de um algoritmo em recomendar uma lista de itens de forma ordenada.\n",
    "\n",
    "### <center> **Predição de Nota** </center>\n",
    "\n",
    "As duas métricas mais comuns quando temos algoritmos que prevem uma nota são o **Erro Médio Absoluto (MAE)** e a **Raiz do Erro Médio Quadrático (RMSE)**. Ambos são medidas de erro, assim, quanto **menor** o valor, **melhor** o método.\n",
    "\n",
    "Você deverá implementar a função `rmse_mae()`, responsável por calcular cada uma das métricas usando as seguintes fórmulas:\n",
    "\n",
    "$$\\text{RMSE}(y, \\hat{y}) = \\sqrt{\\frac{1}{n} \\times \\sum_{i=1}^{n}{(y_i - \\hat{y}_i)^2}}$$\n",
    "\n",
    "$$\\text{MAE}(y, \\hat{y}) = \\frac{1}{n} \\times \\sum_{i=1}^{n}{\\lvert y_i - \\hat{y}_i \\rvert}$$\n",
    "\n",
    "A função irá receber dois vetores como entrada: um com as notas reais ($y$, na variável `real`) e outro com as notas previstas ($\\hat{y}$, na variável `pred`). O retorno será dois números reais, um para cada métrica, variando de $0$ a $\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se seu código estiver correto, o MAE será 1.333 e o RMSE será 1.6330\n",
      "O MAE é 1.3333 e o RMSE é 1.6330\n",
      "\n",
      "Se seu código estiver correto, o MAE será 2.5000 e o RMSE será 2.7386\n",
      "O MAE é 2.5000 e o RMSE é 2.7386\n",
      "\n",
      "Se seu código estiver correto, o MAE será 0.6200 e o RMSE será 0.8379\n",
      "O MAE é 0.6200 e o RMSE é 0.8379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rmse_mae(real, pred):\n",
    "    \"\"\"\n",
    "    Calcula a Raiz do Erro Médio Quadrático e o Erro Médio Absoluto entre os valores de real e pred\n",
    "    \n",
    "    ----------- Entrada -----------\n",
    "       \n",
    "    real: vetor np.array com as notas reais\n",
    "    \n",
    "    pred: vetor np.array com as notas previstas\n",
    "    \n",
    "    ----------- Saída -----------\n",
    "            \n",
    "    rmse_score: Raiz do Erro Médio Quadrático da predição\n",
    "    \n",
    "    mae_score: Erro Médio Absoluto da predição\n",
    "    \"\"\"\n",
    "    \n",
    "    mae_score = 0.0 # Inicializa o MAE\n",
    "    rmse_score = 0.0 # Inicializa o RMSE\n",
    "    \n",
    "    ###########################################################################\n",
    "    ######################### COMPLETE O CÓDIGO AQUI  #########################\n",
    "    # Instruções: você deve calcular o MAE entre as notas reais, em real, e\n",
    "    # previstas, em pred\n",
    "    #    \n",
    "    \n",
    "    rmse_score = np.sum((real - pred) ** 2) / real.shape[0]\n",
    "    rmse_score = np.sqrt(rmse_score)\n",
    "\n",
    "    mae_score = np.sum(np.abs(real - pred)) / real.shape[0]    \n",
    "    \n",
    "    ###########################################################################\n",
    "    \n",
    "    return rmse_score, mae_score\n",
    "\n",
    "# Verifica a implementacao\n",
    "print(\"Se seu código estiver correto, o MAE será 1.333 e o RMSE será 1.6330\")\n",
    "rmse_score, mae_score = rmse_mae(np.array([1, 5, 3]), np.array([1, 3, 1]))\n",
    "print(\"O MAE é {:.4f} e o RMSE é {:.4f}\\n\".format(mae_score, rmse_score))\n",
    "\n",
    "print(\"Se seu código estiver correto, o MAE será 2.5000 e o RMSE será 2.7386\")\n",
    "rmse_score, mae_score = rmse_mae(np.array([5, 5, 5, 5]), np.array([1, 2, 3, 4]))\n",
    "print(\"O MAE é {:.4f} e o RMSE é {:.4f}\\n\".format(mae_score, rmse_score))\n",
    "\n",
    "print(\"Se seu código estiver correto, o MAE será 0.6200 e o RMSE será 0.8379\")\n",
    "rmse_score, mae_score = rmse_mae(np.array([1.5, 2.6, 4.9, 3.4, 2.8]), np.array([1.1, 4.3, 5.0, 3.1, 2.2]))\n",
    "print(\"O MAE é {:.4f} e o RMSE é {:.4f}\\n\".format(mae_score, rmse_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> **Ranqueamento Top-N** </center>\n",
    "\n",
    "Das métricas que avaliam a qualidade do ranqueamento top-N de um algoritmo, implementaremos 4 delas: Precisão, Revocação, F-Medida e NDCG, sendo que a última será implementada por você!\n",
    "\n",
    "Todas as métricas consumirão um dataframe de recomendações que contém três colunas: usuário-alvo, item recomendado e o rank da recomendação (que irá variar de 1 a N). Para implementarmos as métricas, iremos gerar uma base falsa de interações para usar como teste, e uma base falsa de recomendações para usar como a recomendação top-N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interações de teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_usuario</th>\n",
       "      <th>id_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_usuario  id_item\n",
       "0            0        0\n",
       "1            0        1\n",
       "2            1        1\n",
       "3            1       10\n",
       "4            1      100\n",
       "5            2       11\n",
       "6            2       22\n",
       "7            3      100\n",
       "8            4        0\n",
       "9            4       20\n",
       "10           4      100\n",
       "11           4      400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendações\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_usuario</th>\n",
       "      <th>id_item</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_usuario  id_item  rank\n",
       "0            0        0     1\n",
       "1            0        1     2\n",
       "2            0        2     3\n",
       "3            1        0     1\n",
       "4            1       10     2\n",
       "5            1       20     3\n",
       "6            2       10     1\n",
       "7            2       20     2\n",
       "8            2       22     3\n",
       "9            3        1     1\n",
       "10           3       11     2\n",
       "11           3      400     3\n",
       "12           4        0     1\n",
       "13           4       20     2\n",
       "14           4      400     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Monta a base de interações de teste\n",
    "fake_real = pd.DataFrame(\n",
    "    [[0, 0], [0, 1], [1, 1], [1, 10], [1, 100], [2, 11], [2, 22], [3, 100], [4, 0], [4, 20], [4, 100], [4, 400]],\n",
    "    columns=['id_usuario', 'id_item']\n",
    ")\n",
    "print(\"Interações de teste\")\n",
    "display(fake_real)\n",
    "\n",
    "# Monta as recomendações\n",
    "fake_pred = pd.DataFrame(\n",
    "    [[0, 0, 1], [0, 1, 2], [0, 2, 3], \n",
    "     [1, 0, 1], [1, 10, 2], [1, 20, 3],\n",
    "     [2, 10, 1], [2, 20, 2], [2, 22, 3], \n",
    "     [3, 1, 1], [3, 11, 2], [3, 400, 3],\n",
    "     [4, 0, 1], [4, 20, 2], [4, 400, 3]],\n",
    "    columns=['id_usuario', 'id_item', 'rank']\n",
    ")\n",
    "print(\"Recomendações\")\n",
    "display(fake_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Precisão, Revocação e F-Medida**\n",
    "\n",
    "Para avaliar a qualidade dos itens selecionados por cada algoritmo, podemos comparar o conteúdo das listas top-$N$ com os itens consumidos pelos usuários numa base de teste, calculando métricas avaliativas.\n",
    "\n",
    "A precisão busca calcular quantos acertos houveram dentro de tudo que foi recomendado, sendo descrita pela fórmula:\n",
    "\n",
    "$$\\text{Prec} = \\frac{\\text{Qtde de recomendações corretas}}{\\text{Qtde de itens recomendados}} = \\frac{\\text{Qtde de recomendações corretas}}{\\text{Qtde de usuários} \\times N}$$\n",
    "\n",
    "A revocação busca verificar quanto foi acertado de tudo aquilo que realmente poderia ser acertado. É calculada através da fórmula:\n",
    "\n",
    "$$\\text{Rec} = \\frac{\\text{Qtde de recomendações corretas}}{\\text{Qtde de itens consumidos pelos usuários}} = \\frac{\\text{Qtde de recomendações corretas}}{\\text{Tamanho da base de teste}}$$\n",
    "\n",
    "Por fim, a F-Medida é uma forma de equilibrar a Precisão e a Revocação em uma métrica única. É calculada como:\n",
    "\n",
    "$$\\text{F1} = 2 \\times \\frac{\\text{Prec} \\times \\text{Rec}}{\\text{Prec} + \\text{Rec}}$$\n",
    "\n",
    "Você deve implementar a função `precision_recall_f1()`, que recebe como entrada um conjunto de interações real e um previsto, e retorna a precisão, a revocação e a f-medida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se seu código estiver correto, a precisão da recomendação será aprox.: 0.4667\n",
      "A precisão da recomendação é: 0.4667\n",
      "\n",
      "Se seu código estiver correto, a revocação da recomendação será aprox.: 0.5833\n",
      "A revocação da recomendação é: 0.5833\n",
      "\n",
      "Se seu código estiver correto, a f-medida da recomendação será aprox.: 0.5185\n",
      "A f-medida da recomendação é: 0.5185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def precision_recall_f1(real, pred):\n",
    "    \"\"\"\n",
    "    Calcula a precisão, revocação e f-medida da recomendação\n",
    "    \n",
    "    ----------- Entrada -----------\n",
    "       \n",
    "    real: DataFrame com as interações reais, de forma similar a interactions_test\n",
    "    \n",
    "    pred: DataFrame com as recomendações, no formato (usuario, item, rank)\n",
    "    \n",
    "    ----------- Saída -----------\n",
    "    \n",
    "    precision_score: Número real contendo a precisão da recomendação\n",
    "    \n",
    "    recall_score: Número real contendo a revocação da recomendação\n",
    "    \n",
    "    f1_score: Número real contendo a f-medida da recomendação, que deverá ser 0 se precision e recall também forem 0\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    precision_score = 0.0 # Inicializa a precisão\n",
    "    recall_score = 0.0 # Inicializa a revocação\n",
    "    f1_score = 0.0 # Inicializa a f-medida\n",
    "    \n",
    "    # encontra as recomendações feitas corretamente\n",
    "    hits = real.merge(pred, on=['id_usuario', 'id_item'], how='inner')\n",
    "\n",
    "    ###########################################################################\n",
    "    ######################### COMPLETE O CÓDIGO AQUI  #########################\n",
    "    # Instruções: você deve calcular a precisão, a revocação e a f-medida\n",
    "    #  da recomendação\n",
    "    #\n",
    "    \n",
    "    precision_score = hits.shape[0] / pred.shape[0]\n",
    "    recall_score = hits.shape[0] / real.shape[0] \n",
    "    f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
    "\n",
    "    ###########################################################################\n",
    "    \n",
    "    return precision_score, recall_score, f1_score\n",
    "\n",
    "    \n",
    "# Verifica a implementacao\n",
    "prec, rec, f1 = precision_recall_f1(fake_real, fake_pred)\n",
    "\n",
    "print(\"Se seu código estiver correto, a precisão da recomendação será aprox.: 0.4667\")\n",
    "print(\"A precisão da recomendação é: {:.4f}\\n\".format(prec))\n",
    "\n",
    "print(\"Se seu código estiver correto, a revocação da recomendação será aprox.: 0.5833\")\n",
    "print(\"A revocação da recomendação é: {:.4f}\\n\".format(rec))\n",
    "\n",
    "print(\"Se seu código estiver correto, a f-medida da recomendação será aprox.: 0.5185\")\n",
    "print(\"A f-medida da recomendação é: {:.4f}\\n\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ganho Cumulativo Descontado Normalizado (NDCG)**\n",
    "\n",
    "O NDCG é uma métrica que busca avaliar a qualidade do ordenamento, ponderando as recomendações corretas de acordo com a sua posição no rank e usando um decaimento logaritmico.\n",
    "\n",
    "É calculado como:\n",
    "\n",
    "$$NDCG = \\frac{DCG}{IDCG}$$\n",
    "\n",
    "Onde DCG representa o ganho não normalizado, calculado por:\n",
    "\n",
    "$$DCG = \\sum_{u \\in U}{\\sum_{i \\in R_u}{\\frac{rel(i, u)}{log_2(rank_i + 1)}}}$$\n",
    "\n",
    "Onde $U$ é o conjunto de usuários, $R_u$ são os itens recomendados para o usuário, $rank_i$ é a posição do item na recomendação e $rel(i, u)$ é\n",
    "\n",
    "$$rel(i, u) = 0 \\text{ se o usuário } u \\text{ NÃO interagiu com o item } i \\text{, e } 1 \\text{ caso contrário}$$\n",
    "\n",
    "Já IDCG representa o DCG ideal, ou seja, aquele que seria obtido numa recomendação perfeita. É dado por:\n",
    "\n",
    "$$IDCG = \\sum_{u \\in U}{\\sum_{k = 1}^{T_{u_N}}{\\frac{1}{log_2(rank_i + 1)}}}$$\n",
    "\n",
    "Idêntico ao DCG, mas com a suposição que todos os itens foram encontrados e ordenados corretamente. \n",
    "\n",
    "**IMPORTANTE**: por procurar o ganho da recomendação ideal, é importante que o IDCG considere apenas as primeiras $N$ posições. Assim, se um usuário consumiu mais itens que $N$ na base de teste, o IDCG deve ser calculado apenas para $N$ itens, descartando os demais, assim é possível vermos como seria uma recomendação perfeita.\n",
    "\n",
    "Você deve implementar a função `ndgc()`, que recebe como entrada um conjunto de interações real, um previsto (tal como a função `precision_recall_f1`) e o $N$ da recomendação, e retorna o DCG, o IDCG e o NDCG.\n",
    "\n",
    "**Dica**: observe na função `precision_recall_f1()` como foi feita a descoberta das recomendações corretas. Isso pode te ajudar na implementação da função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se seu código estiver correto, o DCG da recomendação será aprox.: 4.8928\n",
      "O DCG da recomendação é: 4.8928\n",
      "\n",
      "Se seu código estiver correto, o IDCG da recomendação será aprox.: 8.5237\n",
      "O IDCG da recomendação é: 8.5237\n",
      "\n",
      "Se seu código estiver correto, o NDCG da recomendação será aprox.: 0.5740\n",
      "O NDCG da recomendação é: 0.5740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ndcg(real, pred, top_n):\n",
    "    \"\"\"\n",
    "    Calcula o DCG, IDCG e NDCG da recomendação\n",
    "    \n",
    "    ----------- Entrada -----------\n",
    "       \n",
    "    real: DataFrame com as interações reais, de forma similar a interactions_test\n",
    "    \n",
    "    pred: DataFrame com as recomendações, no formato (usuario, item, rank)\n",
    "    \n",
    "    top_n: valor de N para a recomendação top-N\n",
    "    \n",
    "    ----------- Saída -----------\n",
    "    \n",
    "    dcg_score: Número real contendo o ganho cumulativo descontado (DCG) da recomendação\n",
    "    \n",
    "    idcg_score: Número real contendo o ganho cumulativo descontado ideal (IDCG) da recomendação\n",
    "    \n",
    "    ndcg_score: Número real contendo o ganho cumulativo descontado normalizado (NDCG) da recomendação\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dcg_score = 0.0   # Inicializa o DCG\n",
    "    idcg_score = 0.0  # Inicializa o IDCG\n",
    "    ndcg_score = 0.0  # Inicializa o NDCG\n",
    "    \n",
    "    ###########################################################################\n",
    "    ######################### COMPLETE O CÓDIGO AQUI  #########################\n",
    "    # Instruções: você deve calcular o DCG, o IDCG e o NDCG da recomendação\n",
    "    #\n",
    "    \n",
    "    for user in set(real['id_usuario']):\n",
    "        # Calcula o dcg\n",
    "        items_real = real[real['id_usuario'] == user]['id_item'].values\n",
    "        items_pred = pred[pred['id_usuario'] == user]['id_item'].values\n",
    "        rel = np.isin(items_pred, items_real)\n",
    "        dcg_score += np.sum(rel / np.log2(np.arange(2, rel.size + 2))) \n",
    "        \n",
    "        # Calcula o idcg\n",
    "        for i in range(1, top_n + 1):\n",
    "            if i > len(items_real):\n",
    "                break    \n",
    "            \n",
    "            idcg_score += 1 / np.log2(i + 1)\n",
    "\n",
    "    # Calcula o ndcg\n",
    "    ndcg_score = dcg_score / idcg_score\n",
    "\n",
    "    ###########################################################################\n",
    "    \n",
    "    return dcg_score, idcg_score, ndcg_score\n",
    "\n",
    "\n",
    "# Verifica a implementacao\n",
    "dcg_score, idcg_score, ndcg_score = ndcg(fake_real, fake_pred, top_n=3)\n",
    "\n",
    "print(\"Se seu código estiver correto, o DCG da recomendação será aprox.: 4.8928\")\n",
    "print(\"O DCG da recomendação é: {:.4f}\\n\".format(dcg_score))\n",
    "\n",
    "print(\"Se seu código estiver correto, o IDCG da recomendação será aprox.: 8.5237\")\n",
    "print(\"O IDCG da recomendação é: {:.4f}\\n\".format(idcg_score))\n",
    "\n",
    "print(\"Se seu código estiver correto, o NDCG da recomendação será aprox.: 0.5740\")\n",
    "print(\"O NDCG da recomendação é: {:.4f}\\n\".format(ndcg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 5: Ajuste de parâmetros\n",
    "\n",
    "Nesta etapa, iremos testar diversos valores para os hiperparâmetros dos modelos, para descobrir, através de uma busca em grande sobre a validação, qual a melhor combinação de parâmetros. Os parâmetros selecionados serão aqueles que minimizarem a métrica RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera os pares usuario-item alvo e as notas reais\n",
    "user_item_targets = interactions_val[['id_usuario', 'id_item']].values\n",
    "real_ratings = interactions_val['nota'].values\n",
    "\n",
    "# --- KNN\n",
    "print(\"---------- KNN ----------\")\n",
    "knn_best_params, knn_best_rmse = None, np.inf\n",
    "for k in [3, 5, 10, 15]:\n",
    "    _, pred_ratings = knn(interactions_matrix, user_item_targets, k=k)\n",
    "    pred_rmse, _ = rmse_mae(real_ratings, pred_ratings)\n",
    "    print('\\tk = {}  |  RMSE: {:.5f}'.format(k, pred_rmse))\n",
    "    if pred_rmse < knn_best_rmse:        \n",
    "        knn_best_rmse = pred_rmse\n",
    "        knn_best_params = {'k': k}\n",
    "print(\"Melhores parâmetros encontrados para o KNN: {}\\n\".format(knn_best_params))\n",
    "\n",
    "# --- SVD\n",
    "print(\"---------- SVD ----------\")\n",
    "svd_best_params, svd_best_rmse = None, np.inf\n",
    "for n_factors in [50, 100]:\n",
    "    for alpha_lr in [0.01, 0.001]:\n",
    "        for lambda_reg in [0.01, 0.001]:        \n",
    "            pred_ratings = svd(interactions_matrix, user_item_targets, n_factors=n_factors, alpha_lr=alpha_lr, lambda_reg=lambda_reg, verbose=False)\n",
    "            rmse_score, _ = rmse_mae(real_ratings, pred_ratings)\n",
    "            print('\\tn_factors = {}  |  alpha_lr = {}  |  lambda_reg = {} |  RMSE: {:.5f}'.format(n_factors, alpha_lr, lambda_reg, pred_rmse))            \n",
    "            if pred_rmse < svd_best_rmse:\n",
    "                svd_best_rmse = pred_rmse\n",
    "                svd_best_params = {'n_factors': n_factors, 'alpha_lr': alpha_lr, 'lambda_reg': lambda_reg}\n",
    "print(\"Melhores parâmetros encontrados para o SVD: {}\\n\".format(svd_best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 6: Avaliação dos algoritmos de recomendação\n",
    "\n",
    "Finalmente, podemos executar nossos algoritmos sobre a base de teste e verificar o resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Junta bases de treinamento e validação**\n",
    "\n",
    "Para enriquecer o treinamento, iremos juntar nossa base de validação com a de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_all = pd.concat([interactions_train, interactions_val]).copy()\n",
    "\n",
    "interactions_matrix = np.zeros((n_items, n_users))\n",
    "interactions_matrix[interactions_all['id_item'], interactions_all['id_usuario']] = interactions_all['nota'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa de predição de nota**\n",
    "\n",
    "Nesta tarefa, os algoritmos irão prever as notas para um conjunto de pares usuário-item, tendo suas predições avaliadas pelo MAE e o RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera pares usuario-item\n",
    "rating_pred_user_item_targets = interactions_test[['id_usuario', 'id_item']].values\n",
    "real_rating_pred = interactions_test['nota'].values\n",
    "\n",
    "# Preve as notas\n",
    "print('Prevendo as notas...')\n",
    "_, knn_rating_pred = knn(interactions_matrix, rating_pred_user_item_targets, **knn_best_params)\n",
    "svd_rating_pred = svd(interactions_matrix, rating_pred_user_item_targets, **svd_best_params)\n",
    "\n",
    "# Calcula os resultados\n",
    "print('\\nCalculando métricas...')\n",
    "knn_rmse, knn_mae = rmse_mae(knn_rating_pred, real_rating_pred)\n",
    "svd_rmse, svd_mae = rmse_mae(svd_rating_pred, real_rating_pred)\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa de ranqueamento top-N**\n",
    "\n",
    "Para recomendar utilizando os algoritmos implementados, teríamos que prever as notas que os usuários-alvo dariam para TODOS os itens não consumidos, o que pode ser extremamente custoso. Em sistemas reais, os algoritmos estariam implementados de forma mais otimizada, além de outras estratégias que poderiam ser adotadas, como uma pré-etapa de clusterização ou uso de recomendadores específicos.\n",
    "\n",
    "Para que o notebook rode em tempo viável e não demande um computador com alta disponibilidade de recursos, iremos gerar uma ranking top-20 apenas para os 10 usuários na base de teste que mais interagiram com itens, avaliando através da Precisão, Revocação, F-Medida e NDCG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupera os usuarios-alvo\n",
    "NUM_TOP_N_USERS = 10\n",
    "top_n_users = interactions_test['id_usuario'].value_counts().sort_values(ascending=False).index.values[:NUM_TOP_N_USERS]\n",
    "\n",
    "# Monta um dataframe com TODOS os pares usuario-item usando os usuarios-alvo\n",
    "top_n_user_item_targets = pd.DataFrame([], columns=['id_usuario', 'id_item']).astype(int)\n",
    "for tnu in top_n_users:    \n",
    "    not_consumed_items = np.where(interactions_matrix[:, tnu]==0)[0]\n",
    "\n",
    "    top_n_user_df = pd.DataFrame(\n",
    "        np.vstack([np.repeat(tnu, len(not_consumed_items)), not_consumed_items]).T,\n",
    "        columns=['id_usuario', 'id_item']\n",
    "    ).astype(int)    \n",
    "\n",
    "    top_n_user_item_targets = pd.concat([top_n_user_item_targets, top_n_user_df])\n",
    "\n",
    "# Preve as notas atribuidas pelos usuarios para todos os itens nao consumidos\n",
    "print('Prevendo as notas...')\n",
    "_, knn_ratings = knn(interactions_matrix, top_n_user_item_targets[['id_usuario', 'id_item']].values)\n",
    "svd_ratings = svd(interactions_matrix, top_n_user_item_targets[['id_usuario', 'id_item']].values)\n",
    "top_n_user_item_targets['nota-knn'] = knn_ratings\n",
    "top_n_user_item_targets['nota-svd'] = svd_ratings\n",
    "\n",
    "# Gera a recomendacao top-20\n",
    "print('\\nMontando listas top-N...')\n",
    "TOP_N = 20\n",
    "\n",
    "knn_top_n = top_n_user_item_targets.sort_values('nota-knn', ascending=False).groupby('id_usuario').head(TOP_N)[['id_usuario', 'id_item']].sort_values('id_usuario')\n",
    "knn_top_n['rank'] = np.tile(np.arange(1, TOP_N+1), NUM_TOP_N_USERS)\n",
    "\n",
    "svd_top_n = top_n_user_item_targets.sort_values('nota-svd', ascending=False).groupby('id_usuario').head(TOP_N)[['id_usuario', 'id_item']].sort_values('id_usuario')\n",
    "svd_top_n['rank'] = np.tile(np.arange(1, TOP_N+1), NUM_TOP_N_USERS)\n",
    "\n",
    "real_top_n = interactions_test[['id_usuario', 'id_item']] # Interacoes de teste\n",
    "\n",
    "# Calcula as metricas\n",
    "print('Calculando métricas...')\n",
    "knn_prec, knn_rec, knn_f1 = precision_recall_f1(real_top_n, knn_top_n)\n",
    "_, _, knn_ndcg = ndcg(real_top_n, knn_top_n, TOP_N)\n",
    "\n",
    "svd_prec, svd_rec, svd_f1 = precision_recall_f1(real_top_n, svd_top_n)\n",
    "_, _, svd_ndcg = ndcg(real_top_n, svd_top_n, TOP_N)\n",
    "\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resultados finais**\n",
    "\n",
    "Os resultados obtidos são bastante interessantes. Ainda que em aplicações reais o SVD geralmente obtenha resultados superiores ao KNN, neste experimento, o algoritmo baseado em vizinhança se saiu superior a fatoração de matriz em todas as métricas, o que mostra que está sendo melhor em aproximar as notas relacionadas aos itens da base de teste e ainda aprender uma boa ordem para os itens que o usuário gostaria de consumir. Ainda assim, não podemos afirmar que um método é superior ao outro porque estamos num cenário pouco condizente com a realidade. Fizemos muitas amostragens dos dados e temos uma base com poucos clientes e baixa significância estatística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    [knn_mae, svd_mae],\n",
    "    [knn_rmse, svd_rmse],\n",
    "    [knn_prec, svd_prec],\n",
    "    [knn_rec, svd_rec],\n",
    "    [knn_f1, svd_f1],\n",
    "    [knn_ndcg, svd_ndcg]\n",
    "], columns=['KNN', 'SVD'], index=['MAE', 'RMSE', 'Prec', 'Rec', 'F1', 'NDCG'])\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
